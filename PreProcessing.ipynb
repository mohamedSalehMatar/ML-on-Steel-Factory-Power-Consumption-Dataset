{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMozaQHF+iMBVumOcsMc5bP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedSalehMatar/Pre-Processing-of-Steel-Factory-Power-Consumption/blob/main/PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLfvVTtOKhdP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datatest= pd.read_csv('/content/gdrive/MyDrive/DataScience/ML Project/test.csv')\n",
        "#print(data1)"
      ],
      "metadata": {
        "id": "iyF__CHrKy3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatrain= pd.read_csv('/content/gdrive/MyDrive/DataScience/ML Project/train.csv')\n",
        "#print(data2)"
      ],
      "metadata": {
        "id": "cRcZiWOtZKtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task Management:\n",
        "\n",
        "Mohamed Saleh -> Data Preprocessing ✔️\n",
        "\n",
        "Mayar         -> Modeling\n",
        "\n",
        "Arwaa         -> Fine tuning"
      ],
      "metadata": {
        "id": "f8oa0c1ZQ1m-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "YSyhpXvuVMvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problems of this dataset:\n",
        "\n",
        "1- WeekStatus, Day_of_week and Load_Type are all categorical ✔️\n",
        "  - Load_Type -> label encoder\n",
        "  - WeekStatus -> one hot\n",
        "  - Day_of_week -> one hot\n",
        "\n",
        "2- missing numerical values ✔️\n",
        "\n",
        "3- date ✔️\n",
        "\n",
        "4- filling outliers with mean ✔️\n",
        "\n",
        "5- duplicates ✔️\n",
        "\n",
        "6- (potential problems)"
      ],
      "metadata": {
        "id": "vOLU2-6plWKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming date to dt type\n",
        "datatrain['date'] = pd.to_datetime(datatrain['date'])\n",
        "\n",
        "#creating new columns for each date data\n",
        "datatrain['year'] = datatrain['date'].dt.year\n",
        "datatrain['month'] = datatrain['date'].dt.month\n",
        "datatrain['day'] = datatrain['date'].dt.day\n",
        "\n",
        "#droping the old date column and reordering the dataframe\n",
        "datatrain = datatrain.drop(datatrain.columns[1], axis=1)\n",
        "neworder = [\n",
        "'Id'\n",
        ",'year'\n",
        ",'month'\n",
        ",'day'\n",
        ",'Lagging_Current_Reactive.Power_kVarh'\n",
        ",'Leading_Current_Reactive_Power_kVarh'\n",
        ",'CO2(tCO2)'\n",
        ",'Lagging_Current_Power_Factor'\n",
        ",'Leading_Current_Power_Factor'\n",
        ",'NSM'\n",
        ",'WeekStatus'\n",
        ",'Day_of_week'\n",
        ",'Load_Type'\n",
        ",'Usage_kWh'\n",
        "]\n",
        "datatrain = datatrain[neworder]\n",
        "\n",
        "#print(datatrain)"
      ],
      "metadata": {
        "id": "vEsKtfLgv83e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(datatrain.corr(), cmap='RdBu', vmin=-1, vmax=1, annot=True)"
      ],
      "metadata": {
        "id": "1DDtfxcTywpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatrain.duplicated().sum()"
      ],
      "metadata": {
        "id": "5LaYbqGcpxs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data null-value amout\n",
        "datatrain.isnull().sum()"
      ],
      "metadata": {
        "id": "h9FT8v4WK3P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling categorical null-value with mode\n",
        "\n",
        "datatrain.iloc[:, 10:12] = datatrain.iloc[:, 10:12].fillna(datatrain.iloc[:, 10:12].mode().iloc[0])\n",
        "datatrain.isnull().sum()"
      ],
      "metadata": {
        "id": "ZlFALC4LN5GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = datatrain.select_dtypes(include=['float', 'int']).columns\n",
        "\n",
        "for feature in numerical_features:\n",
        "    print(f'info of {feature} = ',datatrain[feature].describe())\n",
        "    Q1 = np.percentile(datatrain[feature], 25, method='midpoint')\n",
        "    Q3 = np.percentile(datatrain[feature], 75, method='midpoint')\n",
        "    IQR = Q3 - Q1\n",
        "    print(f'\\nIQR of {feature} = ', IQR)\n",
        "\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    print(f'Lower bound of {feature} = ', lower)\n",
        "    print(f'Upper bound of {feature} = ', upper)\n",
        "\n",
        "    # Replace the outliers with the feature mean\n",
        "    datatrain.loc[(datatrain[feature] < lower) | (datatrain[feature] > upper), feature] = None\n",
        "\n",
        "    print(f'\\nOutliers of {feature} is no more.')"
      ],
      "metadata": {
        "id": "MftJQHZnqiRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatrain.isnull().sum()"
      ],
      "metadata": {
        "id": "EhyBR6g3wM6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling numerical null-value with mean\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "imputer.fit(datatrain.iloc[:, [4, 5, 6, 8, 13]])\n",
        "datatrain.iloc[:, [4, 5, 6, 8, 13]] = imputer.transform(datatrain.iloc[:, [4, 5, 6, 8, 13]])\n",
        "datatrain.isnull().sum()"
      ],
      "metadata": {
        "id": "N-pBxr4MKphv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming categorical date into numeriacal ones\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the data\n",
        "encoded_load_types = label_encoder.fit_transform(datatrain['Load_Type'])\n",
        "datatrain['Load_Type'] = encoded_load_types\n"
      ],
      "metadata": {
        "id": "VLpH9P4Zz0iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatrain = pd.get_dummies(datatrain, columns = ['WeekStatus', 'Day_of_week'])\n",
        "\n",
        "column_to_move = datatrain.pop(\"Usage_kWh\")\n",
        "datatrain.insert(len(datatrain.columns), \"Usage_kWh\", column_to_move)"
      ],
      "metadata": {
        "id": "5524JxjIOJ2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatrain.head(10)"
      ],
      "metadata": {
        "id": "sPsbqN9WH9LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatrain.tail(10)"
      ],
      "metadata": {
        "id": "mFYYNMsNLyvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}